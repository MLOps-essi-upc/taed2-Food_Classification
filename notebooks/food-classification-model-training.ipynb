{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Food-101 Image Classification**","metadata":{}},{"cell_type":"markdown","source":"## **Installation and import of libraries**","metadata":{}},{"cell_type":"code","source":"!pip install mlflow","metadata":{"execution":{"iopub.status.busy":"2023-09-30T22:09:26.775583Z","iopub.execute_input":"2023-09-30T22:09:26.775987Z","iopub.status.idle":"2023-09-30T22:09:35.936687Z","shell.execute_reply.started":"2023-09-30T22:09:26.775960Z","shell.execute_reply":"2023-09-30T22:09:35.935569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install mlflow dagshub","metadata":{"execution":{"iopub.status.busy":"2023-09-30T22:09:35.938918Z","iopub.execute_input":"2023-09-30T22:09:35.939272Z","iopub.status.idle":"2023-09-30T22:09:45.888818Z","shell.execute_reply.started":"2023-09-30T22:09:35.939239Z","shell.execute_reply":"2023-09-30T22:09:45.887697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Import all libraries needed\n\nimport os\n\nimport ast\nimport shutil\nimport urllib\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torchvision import transforms\nimport torchvision.models as models\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\nfrom torchvision.io import read_image\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nfrom torchvision.transforms.functional import to_pil_image\n\nfrom typing import Tuple, Dict, Any, List\nimport matplotlib\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\nfrom typing import Tuple, List\n\nfrom matplotlib.pyplot import imshow\ntorch.set_grad_enabled(True)\n%matplotlib inline\n\nimport mlflow\nimport dagshub","metadata":{"execution":{"iopub.status.busy":"2023-09-30T22:09:45.890576Z","iopub.execute_input":"2023-09-30T22:09:45.890945Z","iopub.status.idle":"2023-09-30T22:09:45.904107Z","shell.execute_reply.started":"2023-09-30T22:09:45.890910Z","shell.execute_reply":"2023-09-30T22:09:45.903089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dagshub.init(\"taed2-Food_Classification\", \"violeta51\", mlflow=True)\n\nmlflow.set_tracking_uri('https://dagshub.com/violeta51/taed2-Food_Classification.mlflow')\nmlflow.set_experiment(experiment_name=\"REPORT INICIAL\")","metadata":{"execution":{"iopub.status.busy":"2023-09-30T22:10:47.962550Z","iopub.execute_input":"2023-09-30T22:10:47.962910Z","iopub.status.idle":"2023-09-30T22:10:48.534025Z","shell.execute_reply.started":"2023-09-30T22:10:47.962883Z","shell.execute_reply":"2023-09-30T22:10:48.532975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Initialization**\n\nLet's set the working enviroment.","metadata":{}},{"cell_type":"code","source":"# set a seed for garantee the replication once we finish get the model\n\nseed = 7767\nnp.random.seed(seed)\n_ = torch.manual_seed(seed)\n_ = torch.cuda.manual_seed(seed)","metadata":{"execution":{"iopub.status.busy":"2023-09-30T22:14:47.680590Z","iopub.execute_input":"2023-09-30T22:14:47.681122Z","iopub.status.idle":"2023-09-30T22:14:47.692240Z","shell.execute_reply.started":"2023-09-30T22:14:47.681085Z","shell.execute_reply":"2023-09-30T22:14:47.691210Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since the model is fairly complex, training it in the GPU will save us time.","metadata":{}},{"cell_type":"code","source":"# we select to work on GPU\n\nif not torch.cuda.is_available():\n       raise RuntimeError(\"You should enable GPU runtime!!\")\ndevice = torch.device(\"cuda\")","metadata":{"execution":{"iopub.status.busy":"2023-09-30T22:14:52.437777Z","iopub.execute_input":"2023-09-30T22:14:52.438102Z","iopub.status.idle":"2023-09-30T22:14:52.473412Z","shell.execute_reply.started":"2023-09-30T22:14:52.438076Z","shell.execute_reply":"2023-09-30T22:14:52.472094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's define some hyper-parameters\n\nhparams = {\n    'log_interval': 200,\n    'epochs' : 20,\n    'batch_size' : 64,\n}\n\nmlflow.log_param(\"log_interval\", hparams[\"log_interval\"])\nmlflow.log_param(\"epochs\", hparams[\"epochs\"])\nmlflow.log_param(\"batch_size\", hparams[\"batch_size\"])","metadata":{"execution":{"iopub.status.busy":"2023-09-30T22:31:34.012201Z","iopub.execute_input":"2023-09-30T22:31:34.013195Z","iopub.status.idle":"2023-09-30T22:31:35.295255Z","shell.execute_reply.started":"2023-09-30T22:31:34.013148Z","shell.execute_reply":"2023-09-30T22:31:35.294457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Load the Data**\nSince the training data are off-line, we need to load them.","metadata":{}},{"cell_type":"code","source":"## Open an image\n\nImage.open('/kaggle/input/data-food/external/apple_pie/1005649.jpg')","metadata":{"execution":{"iopub.status.busy":"2023-09-30T22:32:01.492187Z","iopub.execute_input":"2023-09-30T22:32:01.492499Z","iopub.status.idle":"2023-09-30T22:32:01.589002Z","shell.execute_reply.started":"2023-09-30T22:32:01.492474Z","shell.execute_reply":"2023-09-30T22:32:01.588214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## img dir: directory containing the images\n## annotations file: file containing the labels\n\n## the following code is a modified version of \n## the code extracted from https://pytorch.org/tutorials/beginner/basics/data_tutorial.html \n\nclass CustomImageDataset(Dataset):\n    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n        self.img_labels = annotations_file\n        self.img_dir = img_dir\n        self.transform = transform\n        self.target_transform = target_transform\n\n    def __len__(self): # returns the number of samples in our dataset.\n        return len(self.img_labels)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n        \"\"\"if len(img_path)< 6:\n            print(img_path)\"\"\"\n            \n        image = read_image(img_path)\n\n        to_pil = transforms.ToPILImage()\n        image = to_pil(image)\n        \n        width, height = image.size\n        \n        if width < 224 or height < 224:\n            scale_factor = 512 / max(width, height)\n    \n        # calculate the new dimensions\n            new_width = int(width * scale_factor)\n            new_height = int(height * scale_factor)\n\n            image = image.resize((new_height, new_width))\n        \n        label = self.img_labels.iloc[idx, 1]\n        if self.transform:\n            image = self.transform(image)\n        if self.target_transform:\n            label = self.target_transform(label)\n        \n        return image, label","metadata":{"execution":{"iopub.status.busy":"2023-09-30T22:33:17.537496Z","iopub.execute_input":"2023-09-30T22:33:17.538478Z","iopub.status.idle":"2023-09-30T22:33:17.547087Z","shell.execute_reply.started":"2023-09-30T22:33:17.538434Z","shell.execute_reply":"2023-09-30T22:33:17.545722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define the composed transformation for training\ntrain_transforms = transforms.Compose([transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(p=0.5), transforms.ToTensor(),])\nmlflow.log_param(\"data_augmentation\", \"RandomResizedCrop(224), RandomHorizontalFlip(p=0.5)\")\n\n# define the composed transformation for validation\n# val_transforms = transforms.Compose([transforms.RandomResizedCrop(256),transforms.CenterCrop(224),transforms.ToTensor()])","metadata":{"execution":{"iopub.status.busy":"2023-09-30T22:34:31.728495Z","iopub.execute_input":"2023-09-30T22:34:31.728840Z","iopub.status.idle":"2023-09-30T22:34:32.025550Z","shell.execute_reply.started":"2023-09-30T22:34:31.728807Z","shell.execute_reply":"2023-09-30T22:34:32.024670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## read the folders and load them in a specific class structure\n\nfirst = False\nfirst_first = True\n\n# transform the target 'words' into numerical values, this dictionary will associate these two values\ndictionary = {} \nidx = 0\n\nfor dirname, _, filenames in os.walk('/kaggle/input/data-food/external/'):\n\n    if first == True:\n        label = dirname[len('/kaggle/input/data-food/external/'):]\n        columns = ['file', 'label']\n        target = pd.DataFrame(columns=columns)\n        \n        for filename in filenames:\n            target.loc[len(target)] = [filename, idx]\n        \n        dictionary[idx] =  label\n        sub_dataset = CustomImageDataset(target, dirname, transform = train_transforms)\n        \n        if first_first == True:\n            train_data = sub_dataset\n            first_first = False\n        else:\n            train_data = ConcatDataset([train_data, sub_dataset])\n        \n        idx = idx + 1\n        \n    first = True     ","metadata":{"execution":{"iopub.status.busy":"2023-09-30T22:35:40.993137Z","iopub.execute_input":"2023-09-30T22:35:40.993465Z","iopub.status.idle":"2023-09-30T22:36:07.985751Z","shell.execute_reply.started":"2023-09-30T22:35:40.993438Z","shell.execute_reply":"2023-09-30T22:36:07.984722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show a sample\ntrain_data[2]","metadata":{"execution":{"iopub.status.busy":"2023-09-30T22:36:07.987590Z","iopub.execute_input":"2023-09-30T22:36:07.988128Z","iopub.status.idle":"2023-09-30T22:36:08.117894Z","shell.execute_reply.started":"2023-09-30T22:36:07.988097Z","shell.execute_reply":"2023-09-30T22:36:08.116947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split into training and validation set\ntrain_subset, val_subset = torch.utils.data.random_split(\ntrain_data, [20000, 10000], generator=torch.Generator().manual_seed(7767))","metadata":{"execution":{"iopub.status.busy":"2023-09-30T22:36:48.077810Z","iopub.execute_input":"2023-09-30T22:36:48.078295Z","iopub.status.idle":"2023-09-30T22:36:48.091834Z","shell.execute_reply.started":"2023-09-30T22:36:48.078258Z","shell.execute_reply":"2023-09-30T22:36:48.089873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_subset[14]","metadata":{"execution":{"iopub.status.busy":"2023-09-30T22:36:49.253053Z","iopub.execute_input":"2023-09-30T22:36:49.253371Z","iopub.status.idle":"2023-09-30T22:36:49.272989Z","shell.execute_reply.started":"2023-09-30T22:36:49.253338Z","shell.execute_reply":"2023-09-30T22:36:49.272043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Loader \nOnce the data are loaded in the workspace, we can prepare the data to feed them into the model.","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrain_loader = torch.utils.data.DataLoader(\n    train_subset, \n    batch_size=hparams[\"batch_size\"], \n    shuffle=True,\n    num_workers=1, \n    pin_memory=True,\n)\n\nval_loader = torch.utils.data.DataLoader(\n    val_subset,\n    batch_size=hparams[\"batch_size\"],\n    shuffle=False, \n    num_workers=1,\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-30T22:36:51.377652Z","iopub.execute_input":"2023-09-30T22:36:51.378015Z","iopub.status.idle":"2023-09-30T22:36:51.383241Z","shell.execute_reply.started":"2023-09-30T22:36:51.377986Z","shell.execute_reply":"2023-09-30T22:36:51.382246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Training**","metadata":{}},{"cell_type":"markdown","source":"### Utils: useful functions for the training\nSome useful function will needed later. Here we include some definition of them. ","metadata":{}},{"cell_type":"code","source":"def adjust_learning_rate(\n        optimizer: torch.optim, \n        epoch: int, \n        original_lr: float\n        ) -> None:\n    \n    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n    lr = original_lr * (0.1 ** (epoch // 30))\n    # For some models, different parameters are in different groups with different lr\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr\n\n\ndef compute_accuracy(predicted_batch: torch.Tensor, label_batch: torch.Tensor) -> float:\n    \"\"\"\n    Define the Accuracy metric in the function below by:\n      (1) obtain the maximum for each predicted element in the batch to get the\n        class (it is the maximum index of the num_classes array per batch sample)\n        (look at torch.argmax in the PyTorch documentation)\n      (2) compare the predicted class index with the index in its corresponding\n        neighbor within label_batch\n      (3) sum up the number of affirmative comparisons and return the summation\n\n    Parameters:\n    -----------\n    predicted_batch: torch.Tensor shape: [BATCH_SIZE, N_CLASSES]\n        Batch of predictions\n    label_batch: torch.Tensor shape: [BATCH_SIZE, 1]\n        Batch of labels / ground truths.\n    \"\"\"\n    pred = predicted_batch.argmax(dim=1, keepdim=True) # get the index of the max log-probability \n    acum = pred.eq(label_batch.view_as(pred)).sum().item()\n    return acum\n\n\ndef save_checkpoint(\n        state: 'dict', \n        is_best: bool, \n        filename: str = 'checkpoint.pth.tar'\n        ) -> None:\n    \n    torch.save(state, filename)\n    \n    # save an extra copy if it is the best model yet\n    if is_best:\n        shutil.copyfile(filename, 'model_best.pth.tar')  ","metadata":{"execution":{"iopub.status.busy":"2023-09-30T22:36:59.480425Z","iopub.execute_input":"2023-09-30T22:36:59.480760Z","iopub.status.idle":"2023-09-30T22:36:59.487659Z","shell.execute_reply.started":"2023-09-30T22:36:59.480731Z","shell.execute_reply":"2023-09-30T22:36:59.486639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define the training\n\n","metadata":{}},{"cell_type":"code","source":"# obtain the model from pytorch\nmodel = models.resnet50()\n\n# declare Adam optimizer\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nmlflow.log_param(\"optimizer\", optimizer)\n\n# define the loss function\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2023-09-30T22:37:35.487044Z","iopub.execute_input":"2023-09-30T22:37:35.487399Z","iopub.status.idle":"2023-09-30T22:37:36.199497Z","shell.execute_reply.started":"2023-09-30T22:37:35.487372Z","shell.execute_reply":"2023-09-30T22:37:36.198539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_epoch(\n        train_loader: torch.utils.data.DataLoader, \n        model: torch.nn.Module, \n        optimizer: torch.optim,\n        criterion: torch.nn, \n        epoch: int,\n        log_interval: int,\n        device: torch.device\n        ) -> Tuple[float, float]:\n\n    # switch to train mode (activate the train=True flag inside the model)\n    model.train()\n    \n    train_loss = []\n    acc = 0.\n    avg_weight = 0.1\n    \n    for i in range(len(train_loader)):\n        batch = next(iter(train_loader))\n        images = batch[0]\n        target = batch[1]\n        \n        # set network gradients to 0.\n        optimizer.zero_grad()\n\n        # move images to gpu\n        images = images.to(device)\n        target = target.to(device)\n\n        # forward batch of images through the network\n        output = model(images)\n        loss = criterion(output, target) # Compute the loss\n        #mlflow.log_metric(\"loss_train\",loss)\n\n        # compute gradient and do SGD step\n        loss.backward()\n        optimizer.step()\n        \n        # compute metrics\n        acc += compute_accuracy(output, target)\n        train_loss.append(loss.item())\n        \n        # measure accuracy\n        #acc1, acc5 = accuracy(output, target, topk=(1, 5))\n        #mlflow.log_metric(\"accuracy_train_acc1\",acc1)\n        #mlflow.log_metric(\"accuracy_train_acc5\",acc5)\n\n        if i % log_interval == 0 or i >= len(train_loader)-1:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, i * len(images), len(train_loader.dataset),\n                100. * i / len(train_loader), loss.item()))\n    avg_acc = 100. * acc / len(train_loader.dataset)\n    \n    return np.mean(train_loss), avg_acc ","metadata":{"execution":{"iopub.status.busy":"2023-09-30T22:44:21.569774Z","iopub.execute_input":"2023-09-30T22:44:21.570187Z","iopub.status.idle":"2023-09-30T22:44:21.578441Z","shell.execute_reply.started":"2023-09-30T22:44:21.570141Z","shell.execute_reply":"2023-09-30T22:44:21.577496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad() # decorator: avoid computing gradients\ndef eval_epoch(\n        test_loader: torch.utils.data.DataLoader,\n        model: torch.nn.Module,\n        criterion: torch.nn.functional,\n        ) -> Tuple[float, float]:\n\n    # Dectivate the train=True flag inside the model\n    model.eval()\n    \n    test_loss = 0\n    acc = 0\n    for i in range(len(test_loader)):\n        batch = next(iter(test_loader))\n        data = batch[0]\n        target = batch[1]\n        \n        data, target = data.to(device), target.to(device)\n\n        output = model(data)\n\n        # Apply the loss criterion and accumulate the loss\n        test_loss += criterion(output, target).item()\n\n        # compute number of correct predictions in the batch\n        acc += compute_accuracy(output, target)\n\n    test_loss /= len(test_loader)\n    # Average accuracy across all correct predictions batches now\n    test_acc = 100. * acc / len(test_loader.dataset)\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n        test_loss, acc, len(test_loader.dataset), test_acc,\n        ))\n    return test_loss, test_acc      # ENS RETORNA LES MÈTRIQUES EN LA VALIDACIÓ EN FUNCIÓ DE LES ÈPOQUES","metadata":{"execution":{"iopub.status.busy":"2023-09-30T22:44:22.829388Z","iopub.execute_input":"2023-09-30T22:44:22.829722Z","iopub.status.idle":"2023-09-30T22:44:22.836578Z","shell.execute_reply.started":"2023-09-30T22:44:22.829696Z","shell.execute_reply":"2023-09-30T22:44:22.835668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_net(\n        network: torch.nn.Module,\n        train_loader: torch.utils.data.DataLoader,\n        eval_loader: torch.utils.data.DataLoader,    \n        optimizer: torch.optim,\n        num_epochs: int,\n        plot: bool=True,\n        ) -> Dict[str, List[float]]:\n    \n    \"\"\" Function that trains and evals a network for num_epochs,\n      showing the plot of losses and accs and returning them.\n    \"\"\"\n    tr_losses = []\n    tr_accs = []\n    te_losses = []\n    te_accs = []\n\n    network.to(device)\n    criterion = nn.CrossEntropyLoss()\n\n    for epoch in range(1, num_epochs + 1):\n        tr_loss, tr_acc = train_epoch(train_loader, network, optimizer, criterion, epoch, hparams[\"log_interval\"],device)\n        mlflow.log_metric(\"loss_train\", tr_loss, step=epoch)\n        mlflow.log_metric(\"accuracy_train\", tr_acc, step=epoch)\n        te_loss, te_acc = eval_epoch(eval_loader, network, criterion)\n        mlflow.log_metric(\"loss_eval\", te_loss, step=epoch)\n        mlflow.log_metric(\"accuracy_eval\", te_acc, step=epoch)\n        te_losses.append(te_loss)\n        te_accs.append(te_acc)\n        tr_losses.append(tr_loss)\n        tr_accs.append(tr_acc)\n    rets = {'tr_losses':tr_losses, 'te_losses':te_losses,\n          'tr_accs':tr_accs, 'te_accs':te_accs}\n    if plot:\n        plt.figure(figsize=(10, 8))\n        plt.subplot(2,1,1)\n        plt.xlabel('Epoch')\n        plt.ylabel('NLLLoss')\n        plt.plot(tr_losses, label='train')\n        plt.plot(te_losses, label='eval')\n        plt.legend()\n        plt.subplot(2,1,2)\n        plt.xlabel('Epoch')\n        plt.ylabel('Eval Accuracy [%]')\n        plt.plot(tr_accs, label='train')\n        plt.plot(te_accs, label='eval')\n        plt.legend()\n    return rets","metadata":{"execution":{"iopub.status.busy":"2023-09-30T22:44:23.937560Z","iopub.execute_input":"2023-09-30T22:44:23.938232Z","iopub.status.idle":"2023-09-30T22:44:23.947231Z","shell.execute_reply.started":"2023-09-30T22:44:23.938202Z","shell.execute_reply":"2023-09-30T22:44:23.946281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Parameters","metadata":{}},{"cell_type":"code","source":"def get_nn_nparams(net: torch.nn.Module) -> int:\n  \"\"\"\n  Function that returns all parameters regardless of the require_grad value.\n  https://discuss.pytorch.org/t/how-do-i-check-the-number-of-parameters-of-a-model/4325/6\n  \"\"\"\n  return sum([torch.numel(p) for p in list(net.parameters())])","metadata":{"execution":{"iopub.status.busy":"2023-09-30T22:44:29.404382Z","iopub.execute_input":"2023-09-30T22:44:29.404727Z","iopub.status.idle":"2023-09-30T22:44:29.410334Z","shell.execute_reply.started":"2023-09-30T22:44:29.404701Z","shell.execute_reply":"2023-09-30T22:44:29.409256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's see the number of parameters containing in our network\nprint(\"Number of parameters:\", get_nn_nparams(model))","metadata":{"execution":{"iopub.status.busy":"2023-09-30T22:44:34.095695Z","iopub.execute_input":"2023-09-30T22:44:34.096020Z","iopub.status.idle":"2023-09-30T22:44:34.101394Z","shell.execute_reply.started":"2023-09-30T22:44:34.095993Z","shell.execute_reply":"2023-09-30T22:44:34.100458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train the model and check its performance","metadata":{}},{"cell_type":"code","source":"model_log = train_net(model, train_loader, val_loader, optimizer, hparams[\"epochs\"])","metadata":{"execution":{"iopub.status.busy":"2023-09-30T22:44:37.114166Z","iopub.execute_input":"2023-09-30T22:44:37.114487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_log","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:26:54.319600Z","iopub.execute_input":"2023-09-30T07:26:54.320087Z","iopub.status.idle":"2023-09-30T07:26:54.327358Z","shell.execute_reply.started":"2023-09-30T07:26:54.320045Z","shell.execute_reply":"2023-09-30T07:26:54.326150Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mlflow.end_run()","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:51:03.947592Z","iopub.execute_input":"2023-09-26T17:51:03.948012Z","iopub.status.idle":"2023-09-26T17:51:03.953619Z","shell.execute_reply.started":"2023-09-26T17:51:03.947972Z","shell.execute_reply":"2023-09-26T17:51:03.952574Z"},"trusted":true},"execution_count":null,"outputs":[]}]}